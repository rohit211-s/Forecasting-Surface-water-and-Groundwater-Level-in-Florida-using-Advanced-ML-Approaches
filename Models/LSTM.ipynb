{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02963e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MASE implemented courtesy of sktime - https://github.com/alan-turing-institute/sktime/blob/ee7a06843a44f4aaec7582d847e36073a9ab0566/sktime/performance_metrics/forecasting/_functions.py#L16\n",
    "def mean_absolute_scaled_error(y_true, y_pred):\n",
    "  \"\"\"\n",
    "  Implement MASE (assuming no seasonality of data).\n",
    "  \"\"\"\n",
    "  mae = tf.reduce_mean(tf.abs(y_true - y_pred))\n",
    "\n",
    "\n",
    "  return mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c9d3987",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_preds(y_true, y_pred):\n",
    "  # Make sure float32 (for metric calculations)\n",
    "  y_true = tf.cast(y_true, dtype=tf.float32)\n",
    "  y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
    "\n",
    "  mse = tf.keras.metrics.mean_squared_error(y_true, y_pred) # puts and emphasis on outliers (all errors get squared)\n",
    "  rmse = tf.sqrt(mse)\n",
    "  nrmse = rmse / tf.reduce_mean(y_true)\n",
    "  nse = 1 - (tf.reduce_sum(tf.square(y_true - y_pred)) / tf.reduce_sum(tf.square(y_true - tf.reduce_mean(y_true))))\n",
    "\n",
    "  return {\n",
    "          \"mse\": mse.numpy(),\n",
    "          \"rmse\": rmse.numpy(),\n",
    "          \"nrmse\": nrmse.numpy(),\n",
    "          \"nse\": nse.numpy()\n",
    "         }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaa030a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_preds(model, input_data):\n",
    "  \"\"\"\n",
    "  Uses model to make predictions on input_data.\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  model: trained model\n",
    "  input_data: windowed input data (same kind of data model was trained on)\n",
    "\n",
    "  Returns model predictions on input_data.\n",
    "  \"\"\"\n",
    "  forecast = model.predict(input_data)\n",
    "  return tf.squeeze(forecast) # return 1D array of predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ba9e7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to plot time series data\n",
    "def plot_time_series(timesteps, values, format='.', start=0, end=None, label=None):\n",
    "  \"\"\"\n",
    "  Plots a timesteps (a series of points in time) against values (a series of values across timesteps).\n",
    "\n",
    "  Parameters\n",
    "  ---------\n",
    "  timesteps : array of timesteps\n",
    "  values : array of values across time\n",
    "  format : style of plot, default \".\"\n",
    "  start : where to start the plot (setting a value will index from start of timesteps & values)\n",
    "  end : where to end the plot (setting a value will index from end of timesteps & values)\n",
    "  label : label to show on plot of values\n",
    "  \"\"\"\n",
    "  # Plot the series\n",
    "  plt.plot(timesteps[start:end], values[start:end], format, label=label)\n",
    "  plt.xlabel(\"Time\")\n",
    "  plt.ylabel(\"BTC Price\")\n",
    "  if label:\n",
    "    plt.legend(fontsize=14) # make label bigger\n",
    "  plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee1d5a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x4/87cldz611xz7n8sb7wj3t62r0000gn/T/ipykernel_32381/1216767828.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df=pd.read_csv(\"2328522.csv\",parse_dates=True,index_col=0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Discharge</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daily Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>720.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-02</th>\n",
       "      <td>799.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-03</th>\n",
       "      <td>871.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-04</th>\n",
       "      <td>889.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-05</th>\n",
       "      <td>845.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-27</th>\n",
       "      <td>1680.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-28</th>\n",
       "      <td>1460.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-29</th>\n",
       "      <td>1250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-30</th>\n",
       "      <td>1090.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-31</th>\n",
       "      <td>940.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8186 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Discharge\n",
       "Daily Date           \n",
       "2001-01-01      720.0\n",
       "2001-01-02      799.0\n",
       "2001-01-03      871.0\n",
       "2001-01-04      889.0\n",
       "2001-01-05      845.0\n",
       "...               ...\n",
       "2023-05-27     1680.0\n",
       "2023-05-28     1460.0\n",
       "2023-05-29     1250.0\n",
       "2023-05-30     1090.0\n",
       "2023-05-31      940.0\n",
       "\n",
       "[8186 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "df=pd.read_csv(\"2328522.csv\",parse_dates=True,index_col=0)\n",
    "df = df.dropna()\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c97df952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window: [720.] -> Label: [799.]\n",
      "Window: [799.] -> Label: [871.]\n",
      "Window: [871.] -> Label: [889.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[720.],\n",
       "        [799.],\n",
       "        [871.],\n",
       "        [889.],\n",
       "        [845.]]),\n",
       " array([[799.],\n",
       "        [871.],\n",
       "        [889.],\n",
       "        [845.],\n",
       "        [771.]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "well=df[\"Discharge\"].to_numpy()\n",
    "well\n",
    "\n",
    "timesteps = df.index.to_numpy()\n",
    "\n",
    "timesteps[:10]\n",
    "\n",
    "\n",
    "# Create train and test splits the right way for time series data\n",
    "split_size = int(0.8 * len(well)) # 80% train, 20% test\n",
    "\n",
    "# Create train data splits (everything before the split)\n",
    "X_train, y_train = timesteps[:split_size], well[:split_size]\n",
    "\n",
    "# Create test data splits (everything after the split)\n",
    "X_test, y_test = timesteps[split_size:], well[split_size:]\n",
    "\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)\n",
    "\n",
    "\n",
    "# Create function to label windowed data\n",
    "def get_labelled_windows(x, horizon=1):\n",
    "  \"\"\"\n",
    "  Creates labels for windowed dataset.\n",
    "\n",
    "  E.g. if horizon=1 (default)\n",
    "  Input: [1, 2, 3, 4, 5, 6] -> Output: ([1, 2, 3, 4, 5], [6])\n",
    "  \"\"\"\n",
    "  return x[:, :-horizon], x[:, -horizon:]\n",
    "\n",
    "\n",
    "WINDOW_SIZE=1\n",
    "HORIZON=1\n",
    "def make_windows(x, window_size=1, horizon=1):\n",
    "  \"\"\"\n",
    "  Turns a 1D array into a 2D array of sequential windows of window_size.\n",
    "  \"\"\"\n",
    "  # 1. Create a window of specific window_size (add the horizon on the end for later labelling)\n",
    "  window_step = np.expand_dims(np.arange(window_size+horizon), axis=0)\n",
    "  # print(f\"Window step:\\n {window_step}\")\n",
    "\n",
    "  # 2. Create a 2D array of multiple window steps (minus 1 to account for 0 indexing)\n",
    "  window_indexes = window_step + np.expand_dims(np.arange(len(x)-(window_size+horizon-1)), axis=0).T # create 2D array of windows of size window_size\n",
    "  # print(f\"Window indexes:\\n {window_indexes[:3], window_indexes[-3:], window_indexes.shape}\")\n",
    "\n",
    "  # 3. Index on the target array (time series) with 2D array of multiple window steps\n",
    "  windowed_array = x[window_indexes]\n",
    "\n",
    "  # 4. Get the labelled windows\n",
    "  windows, labels = get_labelled_windows(windowed_array, horizon=horizon)\n",
    "\n",
    "  return windows, labels\n",
    "\n",
    "full_windows, full_labels = make_windows(well, window_size=WINDOW_SIZE, horizon=HORIZON)\n",
    "len(full_windows), len(full_labels)\n",
    "\n",
    "for i in range(3):\n",
    "  print(f\"Window: {full_windows[i]} -> Label: {full_labels[i]}\")\n",
    "\n",
    "def make_train_test_splits(windows, labels, test_split=0.2):\n",
    "  \"\"\"\n",
    "  Splits matching pairs of windows and labels into train and test splits.\n",
    "  \"\"\"\n",
    "  split_size = int(len(windows) * (1-test_split)) # this will default to 80% train/20% test\n",
    "  train_windows = windows[:split_size]\n",
    "  train_labels = labels[:split_size]\n",
    "  test_windows = windows[split_size:]\n",
    "  test_labels = labels[split_size:]\n",
    "  return train_windows, test_windows, train_labels, test_labels\n",
    "\n",
    "train_windows, test_windows, train_labels, test_labels = make_train_test_splits(full_windows, full_labels)\n",
    "len(train_windows), len(test_windows), len(train_labels), len(test_labels)\n",
    "\n",
    "train_windows[:5], train_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaf15b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "# Create a function to implement a ModelCheckpoint callback with a specific filename\n",
    "def create_model_checkpoint(model_name, save_path=\"model_experiments\"):\n",
    "  return tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(save_path, model_name), # create filepath to save model\n",
    "                                            verbose=0, # only output a limited amount of text\n",
    "                                            save_best_only=True) # save only the best model to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ab06884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a032b067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 740.8870INFO:tensorflow:Assets written to: model_experiments/model_4_lstm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_experiments/model_4_lstm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 3s 33ms/step - loss: 739.7902 - val_loss: 387.9121\n",
      "Epoch 2/100\n",
      "50/52 [===========================>..] - ETA: 0s - loss: 182.7730INFO:tensorflow:Assets written to: model_experiments/model_4_lstm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_experiments/model_4_lstm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 22ms/step - loss: 182.9441 - val_loss: 128.3334\n",
      "Epoch 3/100\n",
      "47/52 [==========================>...] - ETA: 0s - loss: 155.9850INFO:tensorflow:Assets written to: model_experiments/model_4_lstm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_experiments/model_4_lstm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 2s 40ms/step - loss: 153.1868 - val_loss: 127.9897\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 152.4704 - val_loss: 130.0463\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 153.4003 - val_loss: 133.2983\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 152.9872 - val_loss: 131.9132\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 154.7088 - val_loss: 129.4985\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 154.1795 - val_loss: 131.7803\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 153.0300 - val_loss: 129.8102\n",
      "Epoch 10/100\n",
      "39/52 [=====================>........] - ETA: 0s - loss: 147.0531INFO:tensorflow:Assets written to: model_experiments/model_4_lstm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_experiments/model_4_lstm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 2s 31ms/step - loss: 152.7801 - val_loss: 127.5844\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 1s 7ms/step - loss: 152.7484 - val_loss: 132.1841\n",
      "Epoch 12/100\n",
      "43/52 [=======================>......] - ETA: 0s - loss: 158.9300INFO:tensorflow:Assets written to: model_experiments/model_4_lstm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_experiments/model_4_lstm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 20ms/step - loss: 153.9739 - val_loss: 127.3720\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - ETA: 0s - loss: 153.4570INFO:tensorflow:Assets written to: model_experiments/model_4_lstm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_experiments/model_4_lstm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 26ms/step - loss: 153.4570 - val_loss: 127.2920\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 152.4371 - val_loss: 127.5931\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 152.8969 - val_loss: 127.5129\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 152.9099 - val_loss: 127.4311\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 152.4644 - val_loss: 127.4322\n",
      "Epoch 18/100\n",
      "44/52 [========================>.....] - ETA: 0s - loss: 159.5829INFO:tensorflow:Assets written to: model_experiments/model_4_lstm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_experiments/model_4_lstm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 2s 45ms/step - loss: 152.7659 - val_loss: 127.1779\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 151.9441 - val_loss: 127.8051\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 152.6133 - val_loss: 128.8022\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 153.1532 - val_loss: 127.6282\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 154.4652 - val_loss: 133.9189\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 154.7245 - val_loss: 136.3984\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 153.1367 - val_loss: 127.9981\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 153.8617 - val_loss: 127.7582\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 156.5101 - val_loss: 127.5628\n",
      "Epoch 27/100\n",
      "38/52 [====================>.........] - ETA: 0s - loss: 157.8837INFO:tensorflow:Assets written to: model_experiments/model_4_lstm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_experiments/model_4_lstm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 2s 43ms/step - loss: 152.0155 - val_loss: 127.1066\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 152.4064 - val_loss: 127.8175\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 155.1622 - val_loss: 128.7407\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 152.5220 - val_loss: 127.7552\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 152.1645 - val_loss: 127.7315\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 152.6672 - val_loss: 127.4643\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 152.7504 - val_loss: 127.9170\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 152.4083 - val_loss: 128.4194\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 153.0191 - val_loss: 127.3287\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 152.9465 - val_loss: 127.2363\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 152.4776 - val_loss: 128.1298\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 152.1591 - val_loss: 127.1956\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 152.5178 - val_loss: 128.4883\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 152.5862 - val_loss: 127.8953\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 152.4733 - val_loss: 130.6048\n",
      "Epoch 42/100\n",
      "38/52 [====================>.........] - ETA: 0s - loss: 156.1633INFO:tensorflow:Assets written to: model_experiments/model_4_lstm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_experiments/model_4_lstm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 27ms/step - loss: 152.2577 - val_loss: 126.9886\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 151.9286 - val_loss: 127.1670\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 151.8308 - val_loss: 128.0999\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 152.7367 - val_loss: 128.0621\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 151.9254 - val_loss: 128.3272\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 152.3767 - val_loss: 127.4839\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 152.2426 - val_loss: 134.7810\n",
      "Epoch 49/100\n",
      "40/52 [======================>.......] - ETA: 0s - loss: 149.1498INFO:tensorflow:Assets written to: model_experiments/model_4_lstm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_experiments/model_4_lstm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 20ms/step - loss: 152.6633 - val_loss: 126.9567\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 151.9115 - val_loss: 127.6618\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 152.5248 - val_loss: 129.6773\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 154.5580 - val_loss: 128.0650\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 153.1285 - val_loss: 127.3923\n",
      "Epoch 54/100\n",
      "50/52 [===========================>..] - ETA: 0s - loss: 154.2752INFO:tensorflow:Assets written to: model_experiments/model_4_lstm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_experiments/model_4_lstm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 25ms/step - loss: 152.4748 - val_loss: 126.9123\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 151.9744 - val_loss: 128.5567\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 153.0837 - val_loss: 127.8678\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 152.0448 - val_loss: 127.4231\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 152.0627 - val_loss: 127.3332\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 151.9858 - val_loss: 133.4279\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 152.6140 - val_loss: 127.3667\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 154.1148 - val_loss: 127.2255\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 152.2096 - val_loss: 131.2542\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 153.4907 - val_loss: 126.9205\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 152.8499 - val_loss: 127.5168\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 151.4612 - val_loss: 134.2836\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 155.0756 - val_loss: 127.2486\n",
      "Epoch 67/100\n",
      "42/52 [=======================>......] - ETA: 0s - loss: 157.0590INFO:tensorflow:Assets written to: model_experiments/model_4_lstm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_experiments/model_4_lstm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 4s 82ms/step - loss: 152.4438 - val_loss: 126.7702\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 152.3083 - val_loss: 127.5225\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 152.4084 - val_loss: 128.3334\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 153.2495 - val_loss: 127.2749\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 152.5414 - val_loss: 127.3195\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 151.8546 - val_loss: 128.1353\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 151.7728 - val_loss: 126.9718\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 151.4955 - val_loss: 132.8819\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 153.1915 - val_loss: 128.9848\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 152.1431 - val_loss: 127.3572\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 152.5729 - val_loss: 127.5854\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 152.4976 - val_loss: 127.0322\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 153.1528 - val_loss: 126.8693\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 153.0072 - val_loss: 133.9344\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 152.7064 - val_loss: 126.8664\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 151.6957 - val_loss: 126.8776\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 151.9895 - val_loss: 129.1430\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 155.6576 - val_loss: 128.1452\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 152.8716 - val_loss: 126.9806\n",
      "Epoch 86/100\n",
      "44/52 [========================>.....] - ETA: 0s - loss: 156.7752INFO:tensorflow:Assets written to: model_experiments/model_4_lstm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_experiments/model_4_lstm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 2s 34ms/step - loss: 153.0132 - val_loss: 126.7290\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 152.5013 - val_loss: 129.6445\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 152.6285 - val_loss: 127.0305\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 152.2862 - val_loss: 131.0521\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 152.2264 - val_loss: 128.1784\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 155.2826 - val_loss: 126.9800\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 151.4332 - val_loss: 126.7885\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 151.7034 - val_loss: 129.9740\n",
      "Epoch 94/100\n",
      "43/52 [=======================>......] - ETA: 0s - loss: 150.3665INFO:tensorflow:Assets written to: model_experiments/model_4_lstm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_experiments/model_4_lstm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 24ms/step - loss: 154.4312 - val_loss: 126.6944\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 152.9836 - val_loss: 128.5010\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 151.3260 - val_loss: 133.3625\n",
      "Epoch 97/100\n",
      "45/52 [========================>.....] - ETA: 0s - loss: 153.4132INFO:tensorflow:Assets written to: model_experiments/model_4_lstm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_experiments/model_4_lstm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 3s 59ms/step - loss: 153.1997 - val_loss: 126.6125\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 151.8889 - val_loss: 127.4033\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 153.0322 - val_loss: 126.8274\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 151.8636 - val_loss: 126.9147\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x28ea0a350>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "# Let's build an LSTM model with the Functional API\n",
    "inputs = layers.Input(shape=(WINDOW_SIZE))\n",
    "x = layers.Lambda(lambda x: tf.expand_dims(x, axis=1))(inputs) # expand input dimension to be compatible with LSTM\n",
    "# print(x.shape)\n",
    "# x = layers.LSTM(128, activation=\"relu\", return_sequences=True)(x) # this layer will error if the inputs are not the right shape\n",
    "x = layers.LSTM(50, activation=\"relu\")(x) # using the tanh loss function results in a massive error\n",
    "# print(x.shape)\n",
    "# Add another optional dense layer (you could add more of these to see if they improve model performance)\n",
    "x = layers.Dense(50, activation=\"relu\")(x)\n",
    "x = layers.Dense(50, activation=\"relu\")(x)\n",
    "output = layers.Dense(HORIZON)(x)\n",
    "model_4 = tf.keras.Model(inputs=inputs, outputs=output, name=\"model_4_lstm\")\n",
    "\n",
    "# Compile model\n",
    "model_4.compile(loss=\"mae\",\n",
    "                optimizer=tf.keras.optimizers.Adam())\n",
    "\n",
    "# Seems when saving the model several warnings are appearing: https://github.com/tensorflow/tensorflow/issues/47554\n",
    "model_4.fit(train_windows,\n",
    "            train_labels,\n",
    "            epochs=100,\n",
    "            verbose=1,\n",
    "            batch_size=128,\n",
    "            validation_data=(test_windows, test_labels),\n",
    "            callbacks=[create_model_checkpoint(model_name=model_4.name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbe2d58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 8ms/step - loss: 128.9058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "128.90579223632812"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4= tf.keras.models.load_model(\"model_experiments/model_4_lstm/\")\n",
    "model_4.evaluate(test_windows, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f25e575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([12126.826 ,  9644.6045,  7200.5684,  5625.3115,  4622.8755,\n",
       "        3906.8494,  3314.9346,  2828.037 ,  2694.3792,  3544.063 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with our LSTM model\n",
    "model_4_preds = make_preds(model_4, test_windows)\n",
    "model_4_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9d8d308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mse': 100051.14, 'rmse': 316.30862, 'nrmse': 0.3237986, 'nse': 0.93930715}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model 5 preds\n",
    "model_4_results = evaluate_preds(y_true=tf.squeeze(test_labels),\n",
    "                                 y_pred=model_4_preds)\n",
    "model_4_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3e4956",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sample1",
   "language": "python",
   "name": "sample1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
